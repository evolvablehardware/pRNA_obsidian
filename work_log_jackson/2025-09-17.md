## Log
- Working to get Squid working on multiple computers
	- I tried connecting two workers to the broker instead of one and it seemed to work
	- It's just an issue with the Mac, probably a network thing? Works fine with run/broker on rosetop and node on pi
- Figure out how we want to use squid? 
	- It seems too good not to use, though there are still some limitations created
	- All we essentially have to do is create a function that maps circuit bitstreams to fitness scores
	- I think the best way might be to create a distribution wrapper around it?
		- The main concern is with choosing what boards to evaluate circuits on, we can solve this issue by selecting what boards we want to deploy squid to when we start an experiment
		- If we want to address more complex fitness metrics (such as evaluate a circuit on each board and average the results), its probably less work to modify Squid than to write our own system
		- The user provides a squid project and selects fpgas from a list of ones available to a central server. This server creates a squid broker and instructs the selected fpgas to connect a squid node to that broker. 
			- Current squid has hardcoded ports, would need to change to allow for multiple brokers on the same device
			- If we run into computation issues on the central server, we can host multiple separate broker server. If we go this route, probably a good idea to design for this in mind
			- We could use squid the intended way and use python? to create instances. This would be really easy. Alternatively, we could use squid as a crate and call the functions ourselves. This would give us access to better analytics since we can directly access data and worker states, but it would also be incredibly painful
				- I think we care less about real time results and more "has stuff crashed?", so its probably best just to parse logs to determine the state of individual workers 
		-  This design makes it easy to launch squid projects, but if we need to modify squid for an experiment, it requires updating the whole system (downtime). 
			- We can still use the modified version of squid locally, but this means disconnecting fpgas from the main system (or keeping test ones)
			- Therefore the main system should probably also provide an interface to connect an fpga to an arbitrary broker, even if its not one provided by the system. 
		- This type of system is independent from the fpga evaluation stuff, so we can work on and test before we have fpga evaluation working
			- we probably do want status updates / crash reports integrated with the fpga stuff though (such as failed to find fpga dev file)
			- the main system could have a separate endpoint for docker containers to report issues, this way squid doesn't have to interface with any of the stuff in the container
## Next
- Look into how the evaluation function is run on the docker container. I want to make sure that it is possible to run some persisting setup stuff (upload code for eval onto pico, connect usb) only the first time. I suspect this can be achieved by just using a function that does different stuff the first time it is evaluated. 
	- It seems simple enough to add an optional argument to the python interface to run the first time

[[work_log_jackson/2025-09-16|prev]] [[work_log_jackson/2025-09-18|next]]
